<!doctype html>
<html>
	<head>
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

		<title>Processing streamed data from a LEGO Truck</title>

		<link type="image/x-icon" rel="shortcut icon" href="img/tdh_truck.jpg" />

		<link rel="stylesheet" href="css/reset.css">
		<link rel="stylesheet" href="css/reveal.css">
		<link rel="stylesheet" href="css/theme/moon.css">

		<!-- Theme used for syntax highlighting of code -->
		<link rel="stylesheet" href="lib/css/monokai.css">

		<!-- Printing and PDF exports -->
		<script>
			var link = document.createElement( 'link' );
			link.rel = 'stylesheet';
			link.type = 'text/css';
			link.href = window.location.search.match( /print-pdf/gi ) ? 'css/print/pdf.css' : 'css/print/paper.css';
			document.getElementsByTagName( 'head' )[0].appendChild( link );
		</script>
	</head>
	<body>
		<div class="reveal">
			<div class="slides">
				<section>
					<h3>Processing streamed data from a LEGO Truck</h3>
					<div style="text-align:center">
						<img src="img/tdh_truck.jpg" alt="TDH LEGO Truck" height="300" width="400" />
					</div>
					<h4>Scala Meetup 2019</h4>
					<p>
						<small>Nelson Costa @ <strong>tb.lx</strong></small>
						<br/>
						<small>nelson.costa85@gmail.com /// nelson.costa@daimler.com</small>
					</p>
				</section>
				<section data-markdown>
					<script type="text/template">
						## Why?

						Trucks (and other IoT devices) are streaming telemetry data at a record rate<!-- .element: class="fragment" data-fragment-index="1" -->

						This data needs to be collected and transformed to build intelligence in near real-time<!-- .element: class="fragment" data-fragment-index="2" -->

						It is paramount to compare the best open source tools capable of data streaming processing<!-- .element: class="fragment" data-fragment-index="3" -->
					</script>
				</section>
				<section data-markdown>
					<script type="text/template">
						## And the world is moving from batch to real-time
						<img data-src="img/batch_vs_streaming.jpeg" />
					</script>
				</section>
				<section data-markdown>
					<script type="text/template">
						## Disclaimer
							* Talk will focus only on streams processing which is a sub-domain of event streaming<!-- .element: class="fragment" data-fragment-index="1" -->
							* And by no means Iâ€™m considering myself an expert on stream processing!<!-- .element: class="fragment" data-fragment-index="2" -->
					</script>
				</section>
				<section data-markdown>
					<script type="text/template">
						## Setup

						**Source** -> LEGO Truck -> Raspberry Pi ->

						**Producers** -> Kafka Producer ->

						**Transformers** -> Kafka Streams | Spark Streaming | Storm | Flink ->

						**Consumers** -> Kafka Consumer ->

						**Target** -> DB, App, StdOut, ...
					</script>
				</section>
				<section data-markdown>
					<script type="text/template">
						## Technologies being compared
						<table>
							<tr>
								<td><img data-src="img/apache_kafka.jpeg" height="70" width="100" /></td>
								<td>Apache Kafka - Kafka Streams</td>
							</tr>
							<tr>
								<td><img data-src="img/apache_spark.png" height="70" width="100" /></td>
								<td>Apache Spark - Spark Streaming</td>
							</tr>
							<tr>
								<td><img data-src="img/apache_storm.jpg" height="70" width="100" /></td>
								<td>Apache Storm</td>
							</tr>
							<tr>
								<td><img data-src="img/apache_flink.jpg" height="70" width="100" /></td>
								<td>Apache Flink</td>
							</tr>
							<tr></tr>
						</table>
					</script>
				</section>
				<section data-markdown>
					<script type="text/template">
						### Apache Kafka -  Kafka Streams

						* Free and open source distributed event processing computation
						* Scalable, fault-tolerant data processing
						* Seamless integration with Kafka
					</script>
				</section>
				<section data-markdown>
					<script type="text/template">
						### Apache Spark - Spark Streaming

						* Free and open source distributed batch and streaming computation
						* Scalable, fault-tolerant data processing
						* Seamless integration with Spark
					</script>
				</section>
				<section data-markdown>
					<script type="text/template">
						### Apache Storm

						* Free and open source distributed realtime computation system
						* Scalable, fault-tolerant data processing
						* Designed to be usable with any programming language (with Apache Thrift)
					</script>
				</section>
				<section data-markdown>
					<script type="text/template">
						### Apache Flink

						* A streaming-first runtime that supports both batch processing and data streaming programs
						* Supports very high throughput and low event latency at the same time
						* Support for event time and out-of-order processing in the DataStream API, based on the Dataflow Model
					</script>
				</section>
				<section data-markdown>
					<script type="text/template">
						### Apache Kafka -  Kafka Streams

						```scala
						def main(args: Array[String]): Unit = {
							val builder = new StreamsBuilder()
							val sourceStream = builder.stream[String, String]("SourceTopic")
							val transformedStream =	sourceStream.flatMapValues(v =>
								util.Arrays.asList(s"kafka-streams-transformation: $v"))
							transformedStream.to("SinkTopic")
							val streams = new KafkaStreams(builder.build(), config)
							streams.start()
						}
						```
					</script>
				</section>
				<section data-markdown>
					<script type="text/template">
						### Apache Spark - Spark Streaming

						```scala
						def main(args: Array[String]): Unit = {
							val sourceDF = spark.readStream.format("kafka")
								.option("kafka.bootstrap.servers", "localhost:9092")
								.option("subscribe", "SourceTopic")
								.load()
							val transformedDF = sourceDF
								.selectExpr("CAST(key AS STRING)", "CAST(value AS STRING)").as[(String, String)]
							transformedDF
								.withColumn("prefix", lit("spark-streaming-transformation: "))
								.withColumn("value", concat(col("prefix"), col("value")))
								.writeStream
								.format("kafka")
								.option("kafka.bootstrap.servers", "localhost:9092")
								.option("topic", "SinkTopic")
								.start()
						}
						```
					</script>
				</section>
				<section data-markdown>
					<script type="text/template">
						### Apache Storm
						```scala
						def main(args: Array[String]): Unit = {
							val builder = new TopologyBuilder()
							val props = new Properties()
							props.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, "localhost:9092")
							val spoutConfig = KafkaSpoutConfig
								.builder("localhost:9092", "SourceTopic")
								.setRecordTranslator(new DefaultRecordTranslator())
								.build()
							builder.setSpout("ReadFromKafka", new KafkaSpout(spoutConfig)).setNumTasks(3)
							builder
								.setBolt("transformMsg", new SimpleBolt(), 3)
								.localOrShuffleGrouping("ReadFromKafka")
							val bolt = new KafkaBolt().withTupleToKafkaMapper(
								new FieldNameBasedTupleToKafkaMapper("key", "transformed"))
									.withProducerProperties(props)
									.withTopicSelector(new DefaultTopicSelector("SinkTopic"))
							builder
								.setBolt("forwardToKafka", bolt, 3)
								.localOrShuffleGrouping("transformMsg")
							StormSubmitter.submitTopology("KafkaTest", new Config(), builder.createTopology())
						}
						```
					</script>
				</section>
				<section data-markdown>
					<script type="text/template">
						### Apache Flink
						```scala
						def main(args: Array[String]): Unit = {

							implicit val typeInfo: TypeInformation[String] = TypeInformation.of(classOf[String])
							val env = StreamExecutionEnvironment.createLocalEnvironment()
							val properties = new Properties()
							properties.put("zookeeper.connect", "localhost:2181")
							properties.put("bootstrap.servers", "localhost:9092")
							env
							.addSource(
								new FlinkKafkaConsumer[String]("SourceTopic",
								KafkaStringSchema,
								properties))
							.map(word => s"flink-transformation: $word")
							.addSink(
								new FlinkKafkaProducer[String]("SinkTopic",
								new KafkaStringSerializationSchema("SinkTopic"),
								properties,
								FlinkKafkaProducer.Semantic.EXACTLY_ONCE))
							env.execute()
						}
						```
					</script>
				</section>
				<section data-markdown>
					<script type="text/template">
						## Comparison

						|   | Kafka Streams | Spark Streaming | Storm | Flink |
						|---|---|---|---|---|
						| Learning Curve  | +/- | +/- | - | - |
						| Performance  | + | +/- | + | + |
						| Stability  | + | - | +/- | + |
					</script>
				</section>
				<section data-markdown>
					<script type="text/template">
						## Thank you!

						Hope you enjoyed it as much as I did!

						All code open-sourced on https://github.com/necosta/streaming-tech-scala-meetup

						## Questions time?
					</script>
				</section>
			</div>
		</div>

		<script src="js/reveal.js"></script>

		<script>
			// More info about config & dependencies:
			// - https://github.com/hakimel/reveal.js#configuration
			// - https://github.com/hakimel/reveal.js#dependencies
			Reveal.initialize({
				controls: true,
				progress: true,
				center: true,
				slideNumber: true,
				history: true,
				autoPlayMedia: true,
				dependencies: [
					{ src: 'plugin/markdown/marked.js' },
					{ src: 'plugin/markdown/markdown.js' },
					{ src: 'plugin/notes/notes.js', async: true },
					{ src: 'plugin/highlight/highlight.js', async: true }
				]
			});
		</script>
	</body>
</html>
