<!doctype html>
<html>
	<head>
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

		<title>Processing stream data from a LEGO Truck</title>

		<link type="image/x-icon" rel="shortcut icon" href="img/tdh_truck.jpg" />

		<link rel="stylesheet" href="css/reset.css">
		<link rel="stylesheet" href="css/reveal.css">
		<link rel="stylesheet" href="css/theme/moon.css">

		<!-- Theme used for syntax highlighting of code -->
		<link rel="stylesheet" href="lib/css/monokai.css">

		<!-- Printing and PDF exports -->
		<script>
			var link = document.createElement( 'link' );
			link.rel = 'stylesheet';
			link.type = 'text/css';
			link.href = window.location.search.match( /print-pdf/gi ) ? 'css/print/pdf.css' : 'css/print/paper.css';
			document.getElementsByTagName( 'head' )[0].appendChild( link );
		</script>
	</head>
	<body>
		<div class="reveal">
			<div class="slides">
				<section>
					<h3>Processing stream data from a LEGO Truck</h3>
					<div style="text-align:center">
						<img src="img/scala.jpeg" alt="Scala Portugal" height="100" width="125" />
						<img src="img/tdh_truck.jpg" alt="TDH LEGO Truck" height="300" width="400" />
						<img src="img/tblx.jpeg" alt="tb.lx Logo" height="100" width="125" />
					</div>
					<h4>Scala Meetup 2019</h4>
					<p>
						<small>Nelson Costa <strong>@ tb.lx</strong></small>
						<br/>
						<small>nelson.costa85@gmail.com /// nelson.costa@daimler.com</small>
					</p>
				</section>
				<section data-markdown>
					<script type="text/template">
						## Why?

						Trucks (and other IoT devices) are streaming telemetry data at a record rate<!-- .element: class="fragment" data-fragment-index="1" -->

						This data needs to be collected and transformed to build intelligence in near real-time<!-- .element: class="fragment" data-fragment-index="2" -->

						We want to compare the best open source tools capable of data streaming processing<!-- .element: class="fragment" data-fragment-index="3" -->
					</script>
				</section>
				<section data-markdown>
					<script type="text/template">
						## And the world is moving from batch to streaming

						<img data-src="img/batch_vs_streaming.jpeg" height="280" width="600" />

						[trends.google.com](https://trends.google.com/trends/explore?date=2016-07-18%202019-08-18&q=%2Fm%2F0fdjtq,%2Fm%2F0zmynvd)
					</script>
				</section>
				<section data-markdown>
					<script type="text/template">
						## Disclaimer

						Talk will focus only on streams processing which is a sub-domain of event streaming<!-- .element: class="fragment" data-fragment-index="1" -->

						By no means I‚Äôm considering myself an expert üòä<!-- .element: class="fragment" data-fragment-index="2" -->
					</script>
				</section>
				<section data-markdown>
					<script type="text/template">
						## Technologies being compared
						<table>
							<tr>
								<td><img data-src="img/apache_kafka.jpeg" height="70" width="100" /></td>
								<td>Apache Kafka - Kafka Streams</td>
							</tr>
							<tr>
								<td><img data-src="img/apache_spark.png" height="70" width="100" /></td>
								<td>Apache Spark - Spark Streaming</td>
							</tr>
							<tr>
								<td><img data-src="img/apache_storm.jpg" height="70" width="100" /></td>
								<td>Apache Storm</td>
							</tr>
							<tr>
								<td><img data-src="img/apache_flink.jpeg" height="70" width="100" /></td>
								<td>Apache Flink</td>
							</tr>
							<tr></tr>
						</table>
					</script>
				</section>
				<section data-markdown>
					<script type="text/template">
						### In common

						* Free and Open Source
						* Distributed, Scalable, Fault-tolerant
						* High throughput and low latency
						* "Delivery guarantees"
					</script>
				</section>
				<section data-markdown>
					<script type="text/template">
						### Apache Kafka - Kafka Streams

						* üëç Very light-weight, designed for high throughput
						* üëç Supports stateful and stateless processing
						* üëç Allows late arrival of data and windowing with out-of-order data
						* üëç Supports elasticity and does not need dedicated cluster
						* üëé Less mature
					</script>
				</section>
				<section data-markdown>
					<script type="text/template">
						### Apache Spark - Spark Streaming

						* üëç Supports Lambda architecture, comes free with Spark
						* üëé Micro-batching (not native streaming)
						* üëé Hard to configure
					</script>
				</section>
				<section data-markdown>
					<script type="text/template">
						### Apache Storm

						* üëç Advance features like event time processing, aggregation, windowing, sessions, watermarks, etc
						* üëç Designed to be usable with any programming language (with Apache Thrift)
						* üëé Community adoption
					</script>
				</section>
				<section data-markdown>
					<script type="text/template">
						### Apache Flink

						* üëç Low latency with high throughput, configurable according to requirements
						* üëç Advance features like event time and out-of-order processing
						* üëé Learning curve
					</script>
				</section>
				<section data-markdown>
					<script type="text/template">
						### Kafka basics

						<img data-src="img/kafka_101.jpg" height="350" width="500" />
					</script>
				</section>
				<section data-markdown>
					<script type="text/template">
						## Setup

						| | |
						|---|---|
						| **Source:** | LEGO Truck + Raspberry Pi -> |
						| **Producers:** | Kafka Producer -> |
						| **Transformers:** | Kafka Streams \| Spark Streaming \| Storm \| Flink -> |
						| **Consumers:** | Kafka Consumer -> |
						| **Target:** | StdOut |
					</script>
				</section>
				<section data-markdown>
					<script type="text/template">
						# Demo
					</script>
				</section>
				<section data-markdown>
					<script type="text/template">
						### Apache Kafka -  Kafka Streams

						```scala
						def main(args: Array[String]): Unit = {
							val builder = new StreamsBuilder()
							val sourceStream = builder.stream[String, String]("SourceTopic")
							val transformedStream =	sourceStream.flatMapValues(v =>
								util.Arrays.asList(s"kafka-streams-transformation: $v"))
							transformedStream.to("SinkTopic")
							val streams = new KafkaStreams(builder.build(), config)
							streams.start()
						}
						```
					</script>
				</section>
				<section data-markdown>
					<script type="text/template">
						### Apache Spark - Spark Streaming

						```scala
						def main(args: Array[String]): Unit = {
							val sourceDF = spark.readStream.format("kafka")
								.option("kafka.bootstrap.servers", "localhost:9092")
								.option("subscribe", "SourceTopic")
								.load()
							val transformedDF = sourceDF
								.selectExpr("CAST(key AS STRING)", "CAST(value AS STRING)").as[(String, String)]
							transformedDF
								.withColumn("prefix", lit("spark-streaming-transformation: "))
								.withColumn("value", concat(col("prefix"), col("value")))
								.writeStream
								.format("kafka")
								.option("kafka.bootstrap.servers", "localhost:9092")
								.option("topic", "SinkTopic")
								.start()
						}
						```
					</script>
				</section>
				<section data-markdown>
					<script type="text/template">
						### Apache Storm
						```scala
						def main(args: Array[String]): Unit = {
							val builder = new TopologyBuilder()
							val props = new Properties()
							props.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, "localhost:9092")
							val spoutConfig = KafkaSpoutConfig
								.builder("localhost:9092", "SourceTopic")
								.setRecordTranslator(new DefaultRecordTranslator())
								.build()
							builder.setSpout("ReadFromKafka", new KafkaSpout(spoutConfig)).setNumTasks(3)
							builder
								.setBolt("transformMsg", new SimpleBolt(), 3)
								.localOrShuffleGrouping("ReadFromKafka")
							val bolt = new KafkaBolt().withTupleToKafkaMapper(
								new FieldNameBasedTupleToKafkaMapper("key", "transformed"))
									.withProducerProperties(props)
									.withTopicSelector(new DefaultTopicSelector("SinkTopic"))
							builder
								.setBolt("forwardToKafka", bolt, 3)
								.localOrShuffleGrouping("transformMsg")
							new LocalCluster().submitTopology("KafkaTest", new Config(), builder.createTopology())
						}
						```
					</script>
				</section>
				<section data-markdown>
					<script type="text/template">
						### Apache Flink
						```scala
						def main(args: Array[String]): Unit = {

							implicit val typeInfo: TypeInformation[String] = TypeInformation.of(classOf[String])
							val env = StreamExecutionEnvironment.createLocalEnvironment()
							val properties = new Properties()
							properties.put("bootstrap.servers", "localhost:9092")
							env
							.addSource(
								new FlinkKafkaConsumer[String]("SourceTopic",
								KafkaStringSchema,
								properties))
							.map(word => s"flink-transformation: $word")
							.addSink(
								new FlinkKafkaProducer[String]("SinkTopic",
								new KafkaStringSerializationSchema("SinkTopic"),
								properties,
								FlinkKafkaProducer.Semantic.EXACTLY_ONCE))
							env.execute()
						}
						```
					</script>
				</section>
				<section data-markdown>
					<script type="text/template">
						## Comparison (opinionated)

						|   | Kafka Streams | Spark Streaming | Apache Storm | Apache Flink |
						|---|---|---|---|---|
						| Learning Curve  | +/- | L | +/- | H |
						| Latency | +/- | - | + | + |
						| Throughput | + | +/- | +/- | +/- |
						| Maturity  | - | +/- | + | + |
					</script>
				</section>
				<section data-markdown>
					<script type="text/template">
						## Community Adoption

						|   | Apache Kafka | Apache Spark | Apache Storm | Apache Flink |
						|---|---|---|---|---|
						| Stars  | 13.4k | 23.2k | 5.8k | 10.5k |
						| Forks  | 7.1k | 19.9k | 4k | 5.6k |
						| Watching  | 1k | 2.1k | 632 | 804 |
						| Repos w/topic  | 345 | 502 | 225 | 339 |
					</script>
				</section>
				<section data-markdown>
					<script type="text/template">
						## Conclusions

						* Stream processing can easily become very challenging<!-- .element: class="fragment" data-fragment-index="1" -->
						* There is no one silver bullet solution for all use-cases<!-- .element: class="fragment" data-fragment-index="2" -->
						* Scala can keep a key position in this area!<!-- .element: class="fragment" data-fragment-index="3" -->
					</script>
				</section>
				<section data-markdown>
					<script type="text/template">
						## Thank you!

						Hope you enjoyed it!

						All code open-sourced on https://github.com/necosta/streaming-tech-scala-meetup

						## Questions time?
					</script>
				</section>
			</div>
		</div>

		<script src="js/reveal.js"></script>

		<script>
			// More info about config & dependencies:
			// - https://github.com/hakimel/reveal.js#configuration
			// - https://github.com/hakimel/reveal.js#dependencies
			Reveal.initialize({
				controls: true,
				progress: true,
				center: true,
				slideNumber: true,
				history: true,
				autoPlayMedia: true,
				dependencies: [
					{ src: 'plugin/markdown/marked.js' },
					{ src: 'plugin/markdown/markdown.js' },
					{ src: 'plugin/notes/notes.js', async: true },
					{ src: 'plugin/highlight/highlight.js', async: true }
				]
			});
		</script>
	</body>
</html>
